import re

def tokenize(code):
    token_specification = [
        ('NUMBER',   r'\d+'),           # Integer
        ('ID',       r'[A-Za-z_]\w*'),  # Identifiers
        ('OP',       r'[+\-*/]'),       # Arithmetic operators
        ('ASSIGN',   r'='),             # Assignment operator
        ('SEMI',     r';'),             # Statement terminator
        ('LPAREN',   r'\('),            # Left Parenthesis
        ('RPAREN',   r'\)'),            # Right Parenthesis
        ('SKIP',     r'[ \t]+'),        # Skip over spaces and tabs
        ('MISMATCH', r'.'),             # Any other character
    ]
    tok_regex = '|'.join(f'(?P<{pair[0]}>{pair[1]})' for pair in token_specification)
    get_token = re.compile(tok_regex).match
    line_number = 1
    line_start = 0
    mo = get_token(code)
    tokens = []
    while mo is not None:
        kind = mo.lastgroup
        value = mo.group(kind)
        if kind == 'NUMBER':
            value = int(value)
        elif kind == 'ID' and value in ('if', 'else', 'while', 'return'):
            kind = value.upper()
        elif kind == 'SKIP':
            mo = get_token(code, mo.end())
            continue
        elif kind == 'MISMATCH':
            raise RuntimeError(f'{value!r} unexpected on line {line_number}')
        tokens.append((kind, value))
        mo = get_token(code, mo.end())
    return tokens
